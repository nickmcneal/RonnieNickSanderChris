{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "import seaborn as sns\n",
    "from pandas.plotting import scatter_matrix\n",
    "sns.set_style(\"whitegrid\")\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.classifier import EnsembleVoteClassifier\n",
    "from mlxtend.feature_selection import ColumnSelector\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "accts = pd.read_csv('data/Cumulative_raw_data.csv')\n",
    "pd.set_option('display.max_colwidth', None) # prevents descriptions from being cut off\n",
    "accts['description'] = accts['description'].values.astype('U') #formating as unicode for Tfidf\n",
    "#accts = accts[:10000] #shortening for exploratory data work to make easier on computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(accts,\n",
    "                                                accts['bot'], #CHANGED FROM TARGET\n",
    "                                                train_size=0.75,\n",
    "                                                shuffle=True,\n",
    "                                                stratify=accts['bot'], #CHANGED FROM TARGET\n",
    "                                                random_state=855)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = accts[['bot']].to_numpy()\n",
    "X = accts[['description']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.25, random_state=1400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = accts['species'] == 'bot'\n",
    "source = accts['source']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train-test split stratifies by target right now, and not by source. We should stratify by both. (Note to Chris: Think of stratifying by a source-target ordered pair.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an array of ordered pairs. Each pair combines the bot/human value of\n",
    "# an account with the source dataset from which the account came. We need this\n",
    "# so that train_test_split can stratify by bot/human value AND data source.\n",
    "\n",
    "# This codeblock takes ten seconds to run on my PC.\n",
    "\n",
    "stratify_guide = np.asarray([(target[acct],source[acct]) for acct in accts.index]).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NEW: One hot encoding bot\n",
    "accts['bot'] = 0\n",
    "accts.loc[accts.species == \"bot\",'bot'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried hyperparameter tuning of `rf_model` but I couldn't really get the accuracy to budge. Adding more attributes to the training data would probably help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators = 100,\n",
    "                                  max_features = 'auto',\n",
    "                                  criterion='entropy')\n",
    "rf_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model\n",
    "\n",
    "y is True for bots, False for humans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall accuracy: 0.7233832630729213\n",
      "\n",
      "vendor-purchased-2019\n",
      "accuracy: 0.16022099447513813\n",
      "\n",
      "verified-2019\n",
      "accuracy: 0.1691842900302115\n",
      "\n",
      "botwiki-2019\n",
      "accuracy: 0.18794835007173602\n",
      "\n",
      "cresci-rtbust-2019\n",
      "accuracy: 0.12572254335260116\n",
      "\n",
      "celebrity-2019\n",
      "accuracy: 0.11441608923440932\n",
      "\n",
      "cresci-stock-2018\n",
      "accuracy: 0.14847457627118643\n",
      "\n",
      "pronbots-2019\n",
      "accuracy: 0.23896873776634417\n",
      "\n",
      "botometer-feedback-2019\n",
      "accuracy: 0.1276595744680851\n",
      "\n",
      "political-bots-2019\n",
      "accuracy: 0.22950819672131148\n",
      "\n",
      "gilani-2017\n",
      "accuracy: 0.15787354007249296\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = rf_model.predict(X_test)\n",
    "print('overall accuracy:', np.sum(pred == y_test)/len(y_test))\n",
    "print()\n",
    "\n",
    "for src in set(source.values):\n",
    "    print(src)\n",
    "    print('accuracy:', np.sum( (pred == y_test) & (source == src) )/source.value_counts()[src])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing Pipes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic KNN (TfidfVectorization, Hashing, CountVectorization) & Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(accts,\n",
    "                                                accts['bot'], #CHANGED FROM TARGET\n",
    "                                                train_size=0.75,\n",
    "                                                shuffle=True,\n",
    "                                                stratify=accts['bot'], #CHANGED FROM TARGET\n",
    "                                                random_state=855)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_t = Pipeline(steps=[#('transform', TfidfVectorizer()), \n",
    "       # ('get_col', ColumnSelector(cols=(20))),\n",
    "        ('tfidf', TfidfVectorizer()),\n",
    "        ('knn', KNeighborsClassifier(n_neighbors = 10))] #20\n",
    "                )\n",
    "\n",
    "pipe_c = Pipeline(steps=[#('transform', TfidfVectorizer()), \n",
    "       # ('get_col', ColumnSelector(cols=(20))),\n",
    "        ('count', CountVectorizer()),\n",
    "        ('knn', KNeighborsClassifier(n_neighbors = 10))]\n",
    "                )\n",
    "\n",
    "pipe_h = Pipeline(steps=[#('transform', TfidfVectorizer()), \n",
    "       # ('get_col', ColumnSelector(cols=(20))),\n",
    "        ('hashing', HashingVectorizer(n_features = 20)),\n",
    "        ('knn', KNeighborsClassifier(n_neighbors = 10))])\n",
    "#pipe_r = Pipeline(steps=[\n",
    "#                ('get_col', ColumnSelector(cols=(32))),\n",
    "#                ('rf_model', RandomForestClassifier(n_estimators = 100, \n",
    "#                                                  max_features = 'auto',\n",
    " #                                                 criterion='entropy'))]) #32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_t = make_pipeline(#('transform', TfidfVectorizer()), \n",
    "        ColumnSelector(cols=(1,20)),\n",
    "        TfidfVectorizer(),\n",
    "        KNeighborsClassifier(n_neighbors = 10) #20\n",
    "                )\n",
    "pipe_c = make_pipeline(#('transform', TfidfVectorizer()), \n",
    "        ColumnSelector(cols=(1,20)),\n",
    "        CountVectorizer(),\n",
    "        KNeighborsClassifier(n_neighbors = 10) #20\n",
    "                )\n",
    "pipe_h = make_pipeline(#('transform', TfidfVectorizer()), \n",
    "        ColumnSelector(cols=(1,20)),\n",
    "        HashingVectorizer(n_features = 20),\n",
    "        KNeighborsClassifier(n_neighbors = 10) #20\n",
    "                )\n",
    "#pipe_r = make_pipeline(\n",
    "#                ('get_col', ColumnSelector(cols=(32))),\n",
    "#                ('rf_model', RandomForestClassifier(n_estimators = 100, \n",
    "#                                                  max_features = 'auto',\n",
    "#                                                 criterion='entropy')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'to_numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-171-026840448b9b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m                               \u001b[1;31m#voting='soft'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                              )\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mvote\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvote\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#['description']\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'to_numpy'"
     ]
    }
   ],
   "source": [
    "#ERROR HERE\n",
    "#error is it needs to handle a (n,) shape numpy array\n",
    "#the data is currently in a dataframe \n",
    "#code works when column selector is removed and data is loaded as accts['description']  for x\n",
    "\n",
    "vote = EnsembleVoteClassifier(clfs=[pipe_t, pipe_c, pipe_h, \n",
    "                                   # pipe_r\n",
    "                                   ], \n",
    "                              #voting='soft'\n",
    "                             )\n",
    "X_train = X_train.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "vote = vote.fit(X_train, y_train.ravel()) #['description'] \n",
    "#eclf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = vote.predict(X_test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our model has a  80.66 % accuracy on the testing set\n"
     ]
    }
   ],
   "source": [
    "print(\"Our model has a \",\n",
    "      np.round(sum(y_predict == y_test.ravel())/len(y_test)*100,2),\n",
    "      \"% accuracy on the testing set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for col in accts.columns: \n",
    "#    print(col) \n",
    "#print(accts.iloc[:,45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False,\n",
       "        'Do you like it gently? üí´ Come in! üòç https://t.co/CGFnsmj94b'],\n",
       "       [False, 'nan'],\n",
       "       [False, 'Do you like fast? Come in! üòªüòªüòª https://t.co/Za2tNtmsBt'],\n",
       "       ...,\n",
       "       [False,\n",
       "        'Explore the stars with @rantzien and @AlaynaMCole of @HornedLlama.'],\n",
       "       [False, 'Cp manager : Mas Fafa - @fafa8888'],\n",
       "       [False, 'Rapper, Hustla, Taurus.']], dtype=object)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_selector = ColumnSelector(cols=(1,20))\n",
    "col_selector.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X_train.reshape)\n",
    "#print(y_train.shape)\n",
    "\n",
    "X_train = X_train.reshape(-1,)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
