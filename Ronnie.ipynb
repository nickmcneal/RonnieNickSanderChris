{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "from pandas.io.json import json_normalize\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful Sections:\n",
    "Regression Notebook 3 \"Why add Qualitative Data to Regression\"\n",
    "\n",
    "Regression Notebook 3 \"How to Choose the Best Model\" - k-fold cross validation\n",
    "\n",
    "Unsupervised Learning Notebook 1 - k-Means clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_labels = pd.read_csv('data/botwiki-2019.tsv', names = ['id', 'identity'], sep = '\\t')\n",
    "human_labels = pd.read_csv('data/verified-2019.tsv', names = ['id', 'identity'], sep = '\\t')\n",
    "bot_labels['bot'] = 1\n",
    "human_labels['bot'] = 0\n",
    "#IMPROVE?\n",
    "# First set all beers as 0\n",
    "#beers_train['Stout'] = 0\n",
    "# Then locate all the stouts and set Stout to 1\n",
    "#beers_train.loc[beers_train.Beer_Type == \"Stout\",'Stout'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if IOUP data rate exceeded: jupyter notebook --NotebookApp.iopub_data_rate_limit=1.0e10\n",
    "\n",
    "#convert json to DataFrame\n",
    "file = open('data/botwiki-2019_tweets.json')\n",
    "file1 = open('data/verified-2019_tweets.json')\n",
    "jsn = json.load(file)\n",
    "jsn1 = json.load(file1)\n",
    "bot_accts = pd.DataFrame(pd.json_normalize(jsn))\n",
    "human_accts = pd.DataFrame(pd.json_normalize(jsn1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge users and labels\n",
    "bot_accts = bot_accts.merge(bot_labels, left_on=bot_accts['user.id'], right_on=bot_labels['id'])\n",
    "human_accts = human_accts.merge(human_labels, left_on=human_accts['user.id'], right_on=human_labels['id'])\n",
    "accts = bot_accts.append(human_accts)\n",
    "#accts.to_csv('bot_wiki_verified_19.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user.id</th>\n",
       "      <th>user.followers_count</th>\n",
       "      <th>user.friends_count</th>\n",
       "      <th>user.listed_count</th>\n",
       "      <th>user.favourites_count</th>\n",
       "      <th>bot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>76235237</td>\n",
       "      <td>3020</td>\n",
       "      <td>790</td>\n",
       "      <td>18</td>\n",
       "      <td>1707</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>2159329092</td>\n",
       "      <td>4074</td>\n",
       "      <td>4239</td>\n",
       "      <td>163</td>\n",
       "      <td>4777</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>25527618</td>\n",
       "      <td>17014</td>\n",
       "      <td>2610</td>\n",
       "      <td>608</td>\n",
       "      <td>7765</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>43654274</td>\n",
       "      <td>367516</td>\n",
       "      <td>20245</td>\n",
       "      <td>5470</td>\n",
       "      <td>10282</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>19084210</td>\n",
       "      <td>55512</td>\n",
       "      <td>11725</td>\n",
       "      <td>1366</td>\n",
       "      <td>2429</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         user.id  user.followers_count  user.friends_count  user.listed_count  \\\n",
       "1982    76235237                  3020                 790                 18   \n",
       "1983  2159329092                  4074                4239                163   \n",
       "1984    25527618                 17014                2610                608   \n",
       "1985    43654274                367516               20245               5470   \n",
       "1986    19084210                 55512               11725               1366   \n",
       "\n",
       "      user.favourites_count  bot  \n",
       "1982                   1707    0  \n",
       "1983                   4777    0  \n",
       "1984                   7765    0  \n",
       "1985                  10282    0  \n",
       "1986                   2429    0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filters accts to only numerical variables for simple knn\n",
    "\n",
    "accts_knn = accts.filter(items = ['user.id', 'user.followers_count', 'user.friends_count', 'user.listed_count', 'user.favourites_count', \n",
    "                    'bot'])\n",
    "\n",
    "accts_knn.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "accts = pd.read_csv('data/Cumulative_raw_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None) # prevents descriptions from being cut off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "accts['description'] = accts['description'].values.astype('U') #formating as unicode for Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "accts = accts[:10000] #shortening for exploratory data work to make easier on computer\n",
    "print(len(accts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>follow_request_sent</th>\n",
       "      <th>has_extended_profile</th>\n",
       "      <th>profile_use_background_image</th>\n",
       "      <th>default_profile_image</th>\n",
       "      <th>profile_background_image_url_https</th>\n",
       "      <th>verified</th>\n",
       "      <th>translator_type</th>\n",
       "      <th>profile_text_color</th>\n",
       "      <th>profile_image_url_https</th>\n",
       "      <th>...</th>\n",
       "      <th>created_at</th>\n",
       "      <th>contributors_enabled</th>\n",
       "      <th>time_zone</th>\n",
       "      <th>protected</th>\n",
       "      <th>default_profile</th>\n",
       "      <th>is_translator</th>\n",
       "      <th>species</th>\n",
       "      <th>source</th>\n",
       "      <th>withheld_in_countries</th>\n",
       "      <th>bot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>602249341</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>https://abs.twimg.com/images/themes/theme4/bg.gif</td>\n",
       "      <td>False</td>\n",
       "      <td>none</td>\n",
       "      <td>000000</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/923924342974578688/k5RCrlSQ_normal.jpg</td>\n",
       "      <td>...</td>\n",
       "      <td>Thu Jun 07 22:16:27 +0000 2012</td>\n",
       "      <td>False</td>\n",
       "      <td>London</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>human</td>\n",
       "      <td>botometer-feedback-2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>797617218511060992</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>https://abs.twimg.com/images/themes/theme1/bg.png</td>\n",
       "      <td>False</td>\n",
       "      <td>none</td>\n",
       "      <td>000000</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/855244571697061888/YDpSuAXy_normal.jpg</td>\n",
       "      <td>...</td>\n",
       "      <td>Sun Nov 13 01:48:58 +0000 2016</td>\n",
       "      <td>False</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>bot</td>\n",
       "      <td>botometer-feedback-2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>889925474</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>https://pbs.twimg.com/profile_background_images/723350044/881da62975b5e0dc69fc5903a094c9df.jpeg</td>\n",
       "      <td>False</td>\n",
       "      <td>none</td>\n",
       "      <td>333333</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/964079832295288832/WSnP8xQ-_normal.jpg</td>\n",
       "      <td>...</td>\n",
       "      <td>Thu Oct 18 23:19:38 +0000 2012</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>human</td>\n",
       "      <td>botometer-feedback-2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96435556</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>https://abs.twimg.com/images/themes/theme6/bg.gif</td>\n",
       "      <td>False</td>\n",
       "      <td>none</td>\n",
       "      <td>333333</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/3114299697/f73cd7211520f13e8121d4ccd5db2481_normal.jpeg</td>\n",
       "      <td>...</td>\n",
       "      <td>Sat Dec 12 22:53:04 +0000 2009</td>\n",
       "      <td>False</td>\n",
       "      <td>Rome</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>bot</td>\n",
       "      <td>botometer-feedback-2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16905397</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>https://pbs.twimg.com/profile_background_images/3248110/DSCF4726.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>regular</td>\n",
       "      <td>666666</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/969705141644410880/MJasCoOk_normal.jpg</td>\n",
       "      <td>...</td>\n",
       "      <td>Wed Oct 22 13:43:42 +0000 2008</td>\n",
       "      <td>False</td>\n",
       "      <td>Bern</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>human</td>\n",
       "      <td>botometer-feedback-2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Unnamed: 0  follow_request_sent  has_extended_profile  \\\n",
       "0           602249341                False                 False   \n",
       "1  797617218511060992                False                  True   \n",
       "2           889925474                False                 False   \n",
       "3            96435556                False                  True   \n",
       "4            16905397                False                 False   \n",
       "\n",
       "   profile_use_background_image  default_profile_image  \\\n",
       "0                         False                  False   \n",
       "1                         False                  False   \n",
       "2                          True                  False   \n",
       "3                          True                  False   \n",
       "4                          True                  False   \n",
       "\n",
       "                                                                profile_background_image_url_https  \\\n",
       "0                                                https://abs.twimg.com/images/themes/theme4/bg.gif   \n",
       "1                                                https://abs.twimg.com/images/themes/theme1/bg.png   \n",
       "2  https://pbs.twimg.com/profile_background_images/723350044/881da62975b5e0dc69fc5903a094c9df.jpeg   \n",
       "3                                                https://abs.twimg.com/images/themes/theme6/bg.gif   \n",
       "4                             https://pbs.twimg.com/profile_background_images/3248110/DSCF4726.jpg   \n",
       "\n",
       "   verified translator_type profile_text_color  \\\n",
       "0     False            none             000000   \n",
       "1     False            none             000000   \n",
       "2     False            none             333333   \n",
       "3     False            none             333333   \n",
       "4     False         regular             666666   \n",
       "\n",
       "                                                                        profile_image_url_https  \\\n",
       "0                   https://pbs.twimg.com/profile_images/923924342974578688/k5RCrlSQ_normal.jpg   \n",
       "1                   https://pbs.twimg.com/profile_images/855244571697061888/YDpSuAXy_normal.jpg   \n",
       "2                   https://pbs.twimg.com/profile_images/964079832295288832/WSnP8xQ-_normal.jpg   \n",
       "3  https://pbs.twimg.com/profile_images/3114299697/f73cd7211520f13e8121d4ccd5db2481_normal.jpeg   \n",
       "4                   https://pbs.twimg.com/profile_images/969705141644410880/MJasCoOk_normal.jpg   \n",
       "\n",
       "   ...                      created_at contributors_enabled  \\\n",
       "0  ...  Thu Jun 07 22:16:27 +0000 2012                False   \n",
       "1  ...  Sun Nov 13 01:48:58 +0000 2016                False   \n",
       "2  ...  Thu Oct 18 23:19:38 +0000 2012                False   \n",
       "3  ...  Sat Dec 12 22:53:04 +0000 2009                False   \n",
       "4  ...  Wed Oct 22 13:43:42 +0000 2008                False   \n",
       "\n",
       "                    time_zone protected  default_profile is_translator  \\\n",
       "0                      London     False            False         False   \n",
       "1  Pacific Time (US & Canada)     False            False         False   \n",
       "2                         NaN     False            False         False   \n",
       "3                        Rome     False            False         False   \n",
       "4                        Bern     False            False         False   \n",
       "\n",
       "   species                   source  withheld_in_countries  bot  \n",
       "0    human  botometer-feedback-2019                    NaN    0  \n",
       "1      bot  botometer-feedback-2019                    NaN    1  \n",
       "2    human  botometer-feedback-2019                    NaN    0  \n",
       "3      bot  botometer-feedback-2019                    NaN    1  \n",
       "4    human  botometer-feedback-2019                    NaN    0  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#One hot encoding bot\n",
    "accts['bot'] = 0\n",
    "accts.loc[accts.species == \"bot\",'bot'] = 1\n",
    "accts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transmuting Text to Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open('sample.txt', 'w', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function TextIOWrapper.close()>"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "for desc in accts['description']:\n",
    "       text.write(desc.strip().replace('\\n+', ''))\n",
    "text.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open('sample.txt', 'r', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit(text)\n",
    "#print(vectorizer.vocabulary_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(len(accts['description'])):\n",
    "#    text = accts['description'][i]\n",
    "#    accts['user.description'][i] = vectorizer.transform(text)\n",
    "#accts['desc_vectorized'] = vectorizer.transform(accts['description'])\n",
    "#accts['desc_vectorized'] = accts['desc_vectorized'].toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accts_copy = accts.copy()\n",
    "#accts_train = accts_copy.sample(frac = 0.75, random_state = 1400)\n",
    "#accts_test = accts_copy.drop(accts_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = accts[['bot']].to_numpy()\n",
    "X = accts[['description']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.25, random_state=1400)\n",
    "accts_tfidf_train = accts_knn.sample(frac = 0.75,  random_state = 876)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(accts['user.description'])\n",
    "vectorizer.fit(X_train['description'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.31335371 7.84335008 9.22964444 ... 9.22964444 9.22964444 9.22964444]\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.idf_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vectorizer.transform(X_train['description'])\n",
    "#vector = vector.toarray()\n",
    "#print(vector.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 10)\n",
    "knn.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our model has a  77.0 % accuracy on the testing set\n"
     ]
    }
   ],
   "source": [
    "X_test = vectorizer.transform(X_test['description'])\n",
    "y_predict = knn.predict(X_test)\n",
    "print(\"Our model has a \",\n",
    "      np.round(sum(y_predict == y_test.ravel())/len(y_test)*100,2),\n",
    "      \"% accuracy on the testing set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = accts[['bot']].to_numpy()\n",
    "X = accts[['description']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.25, random_state=1400)\n",
    "accts_tfidf_train = accts_knn.sample(frac = 0.75,  random_state = 876)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_vectorizer = HashingVectorizer(n_features = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = h_vectorizer.transform(X_train['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=9, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 9)\n",
    "knn.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our model has a  77.24 % accuracy on the testing set\n"
     ]
    }
   ],
   "source": [
    "X_test = h_vectorizer.transform(X_test['description'])\n",
    "y_predict = knn.predict(X_test)\n",
    "print(\"Our model has a \",\n",
    "      np.round(sum(y_predict == y_test.ravel())/len(y_test)*100,2),\n",
    "      \"% accuracy on the testing set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = accts[['bot']].to_numpy()\n",
    "X = accts[['description']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.25, random_state=1400)\n",
    "accts_tfidf_train = accts_knn.sample(frac = 0.75,  random_state = 876)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_vectorizer.fit(X_train['description'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = c_vectorizer.transform(X_train['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 10)\n",
    "knn.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our model has a  80.44 % accuracy on the testing set\n"
     ]
    }
   ],
   "source": [
    "X_test = c_vectorizer.transform(X_test['description'])\n",
    "y_predict = knn.predict(X_test)\n",
    "print(\"Our model has a \",\n",
    "      np.round(sum(y_predict == y_test.ravel())/len(y_test)*100,2),\n",
    "      \"% accuracy on the testing set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining TfidfVectorization, Hashing, CountVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = accts[['bot']].to_numpy()\n",
    "X = accts[['description']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.25, random_state=1400)\n",
    "accts_tfidf_train = accts_knn.sample(frac = 0.75,  random_state = 876)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_vectorizer = TfidfVectorizer()\n",
    "h_vectorizer = HashingVectorizer(n_features = 20)\n",
    "c_vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_vectorizer.fit(X_train['description'].tolist())\n",
    "c_vectorizer.fit(X_train['description'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t_train = t_vectorizer.transform(X_train['description'])\n",
    "X_h_train = h_vectorizer.transform(X_train['description'])\n",
    "X_c_train = c_vectorizer.transform(X_train['description'])\n",
    "#X_train = pd.concat([X_t_train, X_h_train, X_c_train], axis=1)\n",
    "#X_train.head()\n",
    "#X_t_train = pd.DataFrame(X_t_train.todense(), columns=t_vectorizer.get_feature_names())\n",
    "#X_train_full = zip(X_t_train, X_h_train, X_c_train)\n",
    "#print(X_train)\n",
    "#test = pd.DataFrame.sparse.from_spmatrix(X_t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=11, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_t = KNeighborsClassifier(n_neighbors = 11)\n",
    "knn_t.fit(X_t_train, y_train.ravel())\n",
    "\n",
    "knn_h = KNeighborsClassifier(n_neighbors = 11)\n",
    "knn_h.fit(X_h_train, y_train.ravel())\n",
    "\n",
    "knn_c = KNeighborsClassifier(n_neighbors = 11)\n",
    "knn_c.fit(X_c_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t_test = t_vectorizer.transform(X_test['description'])\n",
    "X_h_test = h_vectorizer.transform(X_test['description'])\n",
    "X_c_test = c_vectorizer.transform(X_test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our model has a  75.85 % accuracy on the testing set\n"
     ]
    }
   ],
   "source": [
    "y_t_predict = knn_t.predict(X_t_test)\n",
    "y_h_predict = knn_h.predict(X_h_test)\n",
    "y_c_predict = knn_c.predict(X_c_test)\n",
    "\n",
    "y_predict = np.add(y_t_predict, y_h_predict, y_c_predict)\n",
    "for i in range(len(y_predict)):\n",
    "    if y_predict[i] > 0:\n",
    "        y_predict[i] = 1\n",
    "    else:\n",
    "        y_predict[i] = 0\n",
    "print(\"Our model has a \",\n",
    "      np.round(sum(y_predict == y_test.ravel())/len(y_test)*100,2),\n",
    "      \"% accuracy on the testing set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K-fold cross validation\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.base import clone\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating test train split for knn\n",
    "X = accts[['followers_count', 'friends_count', 'listed_count', 'favourites_count', ]].to_numpy()\n",
    "y = accts[['bot']].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.25, random_state=1400)\n",
    "accts_knn_train = accts_knn.sample(frac = 0.75,  random_state = 876)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our model has a  88.01 % accuracy on the testing set\n"
     ]
    }
   ],
   "source": [
    "print(\"Our model has a \",\n",
    "      np.round(sum(y_predict == y_test.ravel())/len(y_test)*100,2),\n",
    "      \"% accuracy on the testing set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'bot'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-d4a05853f236>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mkmeans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccts_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0morder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"C\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy_x\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         X = check_array(X, accept_sparse='csr', dtype=[np.float64, np.float32],\n\u001b[1;32m--> 859\u001b[1;33m                         order=order, copy=self.copy_x)\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;31m# verify that the number of samples given is larger than k\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    529\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'bot'"
     ]
    }
   ],
   "source": [
    "kmeans.fit(accts_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Train Split\n",
    "#accts_copy = accts.copy()\n",
    "#accts_train = accts_copy.sample(frac = 0.75, random_state = 1400)\n",
    "#accts_test = accts_copy.drop(accts_train.index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
